# -*- coding: utf-8 -*-
"""linear_kernel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g7zrqvbiM6HhRrWokbvFrKepE8UeKaMV
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
from sklearn import svm, preprocessing
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from joblib import dump, load
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

X_train = np.load('/content/drive/MyDrive/828C/proj2/data/mnist/X_train.npy')
y_train = np.load('/content/drive/MyDrive/828C/proj2/data/mnist/y_train.npy')
X_test = np.load('/content/drive/MyDrive/828C/proj2/data/mnist/X_test.npy')
y_test = np.load('/content/drive/MyDrive/828C/proj2/data/mnist/y_test.npy')

linear_clf = svm.LinearSVC(dual=False)
linear_clf.fit(X_train, y_train)

vanilla_train_acc = linear_clf.score(X_train, y_train)

vanilla_test_acc = linear_clf.score(X_test, y_test)

n_components_list = [0.5, 0.6, 0.7, 0.8, 0.9]
train_accuracy = []
test_accuracy = []
components = []

for n_components_ in n_components_list:
  pca = PCA(n_components=n_components_, svd_solver="full")
  X_train_pca = pca.fit_transform(X_train)
  components.append(X_train_pca.shape[1])
  X_test_pca = pca.transform(X_test)

  linear_clf_pca = svm.LinearSVC(dual=False)
  linear_clf_pca.fit(X_train_pca, y_train)

  train_acc = linear_clf_pca.score(X_train_pca, y_train)
  print('Train accuracy: ', train_acc)
  train_accuracy.append(train_acc)

  test_acc = linear_clf_pca.score(X_test_pca, y_test)
  print('Test accuracy: ', test_acc)
  test_accuracy.append(test_acc)

plt.plot(components, train_accuracy, color='b', label='Training accuracy')
plt.plot(components, test_accuracy, color='g', label='Test accuracy')
plt.axhline(y = vanilla_train_acc, color = 'r', label='Vanilla training accuracy')
plt.axhline(y = vanilla_test_acc, color = 'c', label='Vanilla test accuracy')
plt.xlabel('Number of principal components')
plt.ylabel('Accuracy')
plt.title('Linear kernel - PCA - Accuracy vs Number of principal components')
plt.legend()
plt.savefig('/content/drive/MyDrive/828C/proj2/part1/plot/linear_kernel_pca.png')
plt.show()

n_components_list = list(range(2, 10))
train_accuracy = []
test_accuracy = []
components = []


for n_components_ in n_components_list:
  lda = LinearDiscriminantAnalysis(n_components=n_components_)  
  X_train_lda = lda.fit_transform(X_train, y_train)
  components.append(X_train_lda.shape[1])
  X_test_lda = lda.transform(X_test)

  linear_clf_lda = svm.LinearSVC(dual=False)
  linear_clf_lda.fit(X_train_lda, y_train)

  train_acc = linear_clf_lda.score(X_train_lda, y_train)
  print('Train accuracy: ', train_acc)
  train_accuracy.append(train_acc)

  test_acc = linear_clf_lda.score(X_test_lda, y_test)
  print('Test accuracy: ', test_acc)
  test_accuracy.append(test_acc)

plt.plot(components, train_accuracy, color='b', label='Training accuracy')
plt.plot(components, test_accuracy, color='g', label='Test accuracy')
plt.axhline(y = vanilla_train_acc, color = 'r', label='Vanilla training accuracy')
plt.axhline(y = vanilla_test_acc, color = 'c', label='Vanilla test accuracy')
plt.xlabel('Number of linear discriminants')
plt.ylabel('Accuracy')
plt.title('Linear kernel - LDA - Accuracy vs Linear Discriminants')
plt.legend()
plt.savefig('/content/drive/MyDrive/828C/proj2/part1/plot/linear_kernel_lda.png')
plt.show()